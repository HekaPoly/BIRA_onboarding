{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "r2acU8ZtWoNX",
        "a4jchSv7WZWz",
        "EXWxX_lrAasr",
        "CmRBeV2xAlhc",
        "_nXkomwACeDo"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Formation Machine Learning\n",
        "\n",
        "Bienvenue dans ce notebook d’exercices pour la formation en Machine Learning !  \n",
        "Cette formation a pour but d’explorer les concepts fondamentaux du machine learning à travers des implémentations pratiques en Python et l’utilisation de bibliothèques populaires comme `scikit-learn`, `numpy`, `pytorch`, etc.\n",
        "\n",
        "## Contenu\n",
        "\n",
        "Voici un aperçu des sujets couverts dans ce notebook :\n",
        "\n",
        "- Régression linéaire\n",
        "- Régression polynomiale\n",
        "- Régression logistique\n",
        "- Arbres de décision, Forêts aléatoires et Gradient Boosting\n",
        "- Réseaux de neurones\n",
        "\n",
        "## Structure typique d’un exercice\n",
        "\n",
        "Chaque exercice suit généralement la structure suivante :\n",
        "\n",
        "1. **Séparation en jeu d’entraînement / validation**\n",
        "2. **Implémentation et entraînement du modèle**\n",
        "3. **Évaluation du modèle avec des métriques pertinentes**\n",
        "\n",
        "## Pré-requis\n",
        "\n",
        "Avant de commencer, assurez‑vous d’avoir :\n",
        "- **Suivi le MOOC** : [Initiez‑vous au Machine Learning](https://openclassrooms.com/fr/courses/8063076-initiez-vous-au-machine-learning) (OpenClassrooms)\n",
        "- **Lu les chapitres 1 à 4** de la série [Neural Networks](https://www.3blue1brown.com/topics/neural-networks) (3Blue1Brown)\n",
        "- **Réalisé le tutoriel** : [PyTorch Basics](https://docs.pytorch.org/tutorials/beginner/basics/intro.html)\n",
        "\n",
        "## Pour aller plus loin\n",
        "\n",
        "Voici quelques ressources pour approfondir vos connaissances en Machine Learning au-delà de ce qui a été présenté dans ce notebook:\n",
        "\n",
        "- [MIT 6.036 - Introduction to Machine Learning](https://openlearninglibrary.mit.edu/courses/course-v1:MITx+6.036+1T2019/course/) ⭐⭐\n",
        "- [MIT 6.S191 - Introduction to Deep Learning](https://www.youtube.com/watch?v=alfdI7S6wCY&list=PLtBw6njQRU-rwp5__7C0oIVt26ZgjG9NI) ⭐⭐\n",
        "- [MIT 18.657 - Mathematics of Machine Learning](https://ocw.mit.edu/courses/18-657-mathematics-of-machine-learning-fall-2015/download/) ⭐⭐⭐\n",
        "- [PolyMTL INF8245E - Machine Learning (Vidéos)](https://www.youtube.com/watch?v=-6ChHxllZVU&list=PLImtCgowF_ETupFCGQqmvS_2nqErZbifm) ⭐⭐\n",
        "- [PolyMTL INF8245E - Machine Learning (Notes)](https://drive.google.com/drive/folders/1xUqzxJK5NbAxUZOInpTBAAQk8iwKSKVS) ⭐⭐\n",
        "- [PolyMTL INF8359DE - Reinforcement Learning](https://www.youtube.com/watch?v=J9JZyyPCJcQ&list=PLImtCgowF_ES_JdF_UcM60EXTcGZg67Ua) ⭐⭐\n",
        "- [PolyMTL MTH3302 - Méthodes probabilistes et statistiques pour l'IA](https://github.com/decorJim/mth3302) ⭐⭐⭐\n",
        "- [An Introduction to Statistical Learning — Gareth James, Daniela Witten, Trevor Hastie & Robert Tibshirani](https://www.statlearning.com/) ⭐⭐\n",
        "- [Statistical Learning Theory — Vladimir N. Vapnik](https://www.wiley.com/en-us/Statistical-Learning-Theory-9780471030034) ⭐⭐⭐\n",
        "\n",
        "Légende:\n",
        "- ⭐: pas (ou peu) de pré‑requis en ML/programmation/maths.\n",
        "- ⭐⭐: notions de base acquises; à l’aise avec Python + algèbre linéaire + probabilités.\n",
        "- ⭐⭐⭐: solide bagage mathématique (analyse, probabilités, statistiques, optimisation) et envie de rigueur théorique."
      ],
      "metadata": {
        "id": "fkfMuHBm4-ms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "r2acU8ZtWoNX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "UCKOK6-649D9"
      },
      "outputs": [],
      "source": [
        "import unittest\n",
        "from typing import Tuple\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torchvision import datasets, transforms\n",
        "from sklearn.datasets import fetch_california_housing, load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.metrics import (\n",
        "    mean_squared_error,\n",
        "    root_mean_squared_error,\n",
        "    r2_score,\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    confusion_matrix,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Régression Linéaire\n",
        "\n",
        "Dans cet exercice, vous allez créer un modèle de machine learning pour **prédire la valeur médiane des maisons (`target`, en centaines de milliers $) à partir du revenu médian (`MedInc`) d’un district californien**.  \n",
        "Vous ne disposerez que d’une seule variable explicative, ce qui facilitera la visualisation de la droite de régression.\n",
        "\n",
        "### Objectifs pédagogiques\n",
        "1. **Comprendre** les étapes essentielles d’un workflow de *machine learning* :  \n",
        "   préparation des données, entraînement, validation et visualisation.  \n",
        "2. **Implémenter** les fonctions `train`, `eval` et `main` afin de :  \n",
        "   - séparer le jeu de données en `train` / `validation` (`train_test_split`) ;  \n",
        "   - entraîner un modèle `LinearRegression` de *scikit-learn* ;  \n",
        "   - calculer et afficher les métriques : **RMSE**, **MSE** et **R²** ;  \n",
        "   - récupérer le coefficient et l’ordonnée à l’origine appris.  \n",
        "3. **Interpréter** la pente obtenue pour relier le revenu aux prix des maisons et discuter de la qualité de la prédiction.\n",
        "\n",
        "### Jeu de données\n",
        "Nous utiliserons le **California Housing Dataset** disponible dans *scikit-learn*.\n",
        "\n",
        "*Référence utile : https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html*"
      ],
      "metadata": {
        "id": "a4jchSv7WZWz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Code fourni"
      ],
      "metadata": {
        "id": "0tNDallDXavH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot(model: LinearRegression, X: np.ndarray, y: np.ndarray):\n",
        "    plt.figure(figsize=(7, 5))\n",
        "    plt.scatter(X, y, s=10, alpha=0.4, label=\"Données brutes\")\n",
        "    x_line = np.linspace(X.min(), X.max(), 100).reshape(-1, 1)\n",
        "    y_line = model.predict(x_line)\n",
        "    plt.plot(x_line, y_line, color=\"red\", lw=2, label=\"Droite de régression\")\n",
        "    plt.xlabel(\"Revenu médian\")\n",
        "    plt.ylabel(\"Prix médian d'un maison\")\n",
        "    plt.title(\"Le marché immobilier californien - régression linéaire simple\")\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "UcrY-Y9fXZ-0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Code à compléter"
      ],
      "metadata": {
        "id": "aQEYKHYYXiwB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(X_train: np.ndarray, y_train: np.ndarray) -> LinearRegression:\n",
        "    \"\"\"\n",
        "    Crée et entraîne un modèle de régression linéaire.\n",
        "    Retourne le modèle entraîné.\n",
        "    \"\"\"\n",
        "\n",
        "    # TODO: Effectuer la régression linéaire sur l'ensemble d'entraînement\n",
        "    raise NotImplementedError()\n",
        "\n",
        "def eval(model: LinearRegression, X_val: np.ndarray, y_val: np.ndarray) -> dict[str, float]:\n",
        "    \"\"\"\n",
        "    Évalue le modèle sur l'ensemble de validation et renvoie les métriques.\n",
        "    \"\"\"\n",
        "\n",
        "    # TODO: Effectuer la validation du modèle sur l'ensemble de validation\n",
        "    raise NotImplementedError()\n",
        "\n",
        "def main(test_ratio: float = 0.2, random_state: int = 0):\n",
        "    data = fetch_california_housing()\n",
        "    X = data.data[:, [data.feature_names.index(\"MedInc\")]]\n",
        "    y = data.target\n",
        "\n",
        "    # TODO: Séparer votre jeu de données en ensembles d'entraînement et de validation\n",
        "\n",
        "    # TODO: Instancier votre modèle entraîné et effectuer la validation du modèle\n",
        "\n",
        "    # TODO: Afficher les métriques, les coefficients et l'ordonnée à l'origine\n",
        "    #       du modèle\n",
        "\n",
        "    # TODO: Afficher la visualisation du jeu de données avec la droite de\n",
        "    #       régression linéaire à l'aide de la fonction plot\n",
        "    raise NotImplementedError()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "e9sVodcu5Tn3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "599595fd-7a3f-4d79-f628-028b3e21c5e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NotImplementedError",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4-3459358044.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-4-3459358044.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(test_ratio, random_state)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;31m# TODO: Afficher les visualisations à partir de la fonction plot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotImplementedError\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tests"
      ],
      "metadata": {
        "id": "d50IeWPYCBnD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EXPECTED = {\n",
        "    \"coef\": 0.4203217769894005,\n",
        "    \"intercept\": 0.4432063522765708,\n",
        "    \"rmse\": 0.8494105152406937,\n",
        "    \"mse\": 0.7214982234014606,\n",
        "    \"r2\": 0.4466846804895943,\n",
        "}\n",
        "\n",
        "TOL = 1e-2\n",
        "\n",
        "class TestLinearRegression(unittest.TestCase):\n",
        "    def test_train_learns_coefficients(self):\n",
        "        rng = np.random.default_rng(42)\n",
        "        X = rng.random((300, 1))\n",
        "        true_coef, true_intercept = 4.2, -1.3\n",
        "        y = true_coef * X.squeeze() + true_intercept\n",
        "\n",
        "        model = train(X, y)\n",
        "\n",
        "        self.assertIsInstance(model, LinearRegression)\n",
        "        self.assertAlmostEqual(model.coef_[0], true_coef, delta=TOL)\n",
        "        self.assertAlmostEqual(model.intercept_, true_intercept, delta=TOL)\n",
        "\n",
        "    def test_eval_returns_perfect_metrics(self):\n",
        "        X = np.array([[0.0], [1.0], [2.0], [3.0]])\n",
        "        y = np.array([0.0, 2.0, 4.0, 6.0])\n",
        "\n",
        "        perfect_model = LinearRegression().fit(X, y)\n",
        "        metrics = eval(perfect_model, X, y)\n",
        "\n",
        "        self.assertSetEqual(set(metrics), {\"rmse\", \"mse\", \"r2\"})\n",
        "        self.assertAlmostEqual(metrics[\"rmse\"], 0.0, delta=TOL)\n",
        "        self.assertAlmostEqual(metrics[\"mse\"], 0.0, delta=TOL)\n",
        "        self.assertAlmostEqual(metrics[\"r2\"], 1.0, delta=TOL)\n",
        "\n",
        "    def test_california_exact_values(self):\n",
        "        data = fetch_california_housing()\n",
        "        X = data.data[:, [data.feature_names.index(\"MedInc\")]]\n",
        "        y = data.target\n",
        "\n",
        "        X_train, X_val, y_train, y_val = train_test_split(\n",
        "            X, y, test_size=0.2, random_state=0, shuffle=True\n",
        "        )\n",
        "\n",
        "        model = train(X_train, y_train)\n",
        "        metrics = eval(model, X_val, y_val)\n",
        "\n",
        "        self.assertAlmostEqual(model.coef_[0], EXPECTED[\"coef\"], delta=TOL,\n",
        "                               msg=\"Coefficient drift\")\n",
        "        self.assertAlmostEqual(model.intercept_, EXPECTED[\"intercept\"], delta=TOL,\n",
        "                               msg=\"Intercept drift\")\n",
        "\n",
        "        self.assertAlmostEqual(metrics[\"rmse\"], EXPECTED[\"rmse\"], delta=TOL,\n",
        "                               msg=\"RMSE drift\")\n",
        "        self.assertAlmostEqual(metrics[\"mse\"], EXPECTED[\"mse\"], delta=TOL,\n",
        "                               msg=\"MSE drift\")\n",
        "        self.assertAlmostEqual(metrics[\"r2\"], EXPECTED[\"r2\"], delta=TOL,\n",
        "                               msg=\"R² drift\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    unittest.main(argv=['first-arg-is-ignored', 'TestLinearRegression'], exit=False, verbosity=2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zq7Xo2TuEW2y",
        "outputId": "145bab6d-076b-4c7d-e9f3-021e03a706d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "test_california_exact_values (__main__.TestLinearRegression.test_california_exact_values) ... ERROR\n",
            "test_eval_returns_perfect_metrics (__main__.TestLinearRegression.test_eval_returns_perfect_metrics) ... ERROR\n",
            "test_train_learns_coefficients (__main__.TestLinearRegression.test_train_learns_coefficients) ... ERROR\n",
            "\n",
            "======================================================================\n",
            "ERROR: test_california_exact_values (__main__.TestLinearRegression.test_california_exact_values)\n",
            "----------------------------------------------------------------------\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-26-2869508149.py\", line 45, in test_california_exact_values\n",
            "    model = train(X_train, y_train)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-23-2994106817.py\", line 9, in train\n",
            "    model.fit(X_train, y_train)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1389, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py\", line 1231, in fit\n",
            "    check_classification_targets(y)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/multiclass.py\", line 222, in check_classification_targets\n",
            "    raise ValueError(\n",
            "ValueError: Unknown label type: continuous. Maybe you are trying to fit a classifier, which expects discrete classes on a regression target with continuous values.\n",
            "\n",
            "======================================================================\n",
            "ERROR: test_eval_returns_perfect_metrics (__main__.TestLinearRegression.test_eval_returns_perfect_metrics)\n",
            "----------------------------------------------------------------------\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-26-2869508149.py\", line 29, in test_eval_returns_perfect_metrics\n",
            "    metrics = eval(perfect_model, X, y)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-23-2994106817.py\", line 23, in eval\n",
            "    \"Precision\": precision_score(y_val, y_pred),\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\", line 216, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\", line 2247, in precision_score\n",
            "    p, _, _, _ = precision_recall_fscore_support(\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\", line 189, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\", line 1830, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\", line 1613, in _check_set_wise_labels\n",
            "    raise ValueError(\n",
            "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
            "\n",
            "======================================================================\n",
            "ERROR: test_train_learns_coefficients (__main__.TestLinearRegression.test_train_learns_coefficients)\n",
            "----------------------------------------------------------------------\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-26-2869508149.py\", line 18, in test_train_learns_coefficients\n",
            "    model = train(X, y)\n",
            "            ^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-23-2994106817.py\", line 9, in train\n",
            "    model.fit(X_train, y_train)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1389, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py\", line 1231, in fit\n",
            "    check_classification_targets(y)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/multiclass.py\", line 222, in check_classification_targets\n",
            "    raise ValueError(\n",
            "ValueError: Unknown label type: continuous. Maybe you are trying to fit a classifier, which expects discrete classes on a regression target with continuous values.\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "Ran 3 tests in 0.101s\n",
            "\n",
            "FAILED (errors=3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Régression polynomiale\n",
        "\n",
        "Dans cet exercice, vous allez créer un modèle de *machine learning* pour **modéliser une relation non linéaire** entre une variable explicative `X` et une cible `y`.  \n",
        "Le but est de comparer la **régression linéaire** classique à une **régression polynomiale** de **degré *d*** (par défaut : **3**) obtenue via `PolynomialFeatures`.\n",
        "\n",
        "### Objectifs pédagogiques\n",
        "1. **Comprendre** les étapes essentielles d'un workflow de *machine learning* :  préparation des données, entraînement, validation et visualisation.  \n",
        "2. **Implémenter** les fonctions `train_linear`, `eval_linear`, `train_poly`, `eval_poly` et `main` afin de :  \n",
        "   - séparer le jeu de données en `train` / `validation` (`train_test_split`) ;  \n",
        "   - entraîner un modèle `LinearRegression` **et** un modèle polynomiale ;  \n",
        "   - calculer et afficher les métriques : **RMSE**, **MSE** et **R²**.\n",
        "3. **Interpréter** l'impact du degré du polynôme : détection du sous-apprentissage (degré trop faible) et du sur-apprentissage (degré trop élevé).\n",
        "\n",
        "### Jeu de données\n",
        "Nous utiliserons une fonction utilitaire pour générer un jeu de données :\n",
        "\n",
        "```python\n",
        "X, y = generate_polynomial_data(n_samples=500, noise=3, random_state=0)\n",
        "```"
      ],
      "metadata": {
        "id": "EXWxX_lrAasr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Code fourni"
      ],
      "metadata": {
        "id": "rsEKjFU9-MVT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_polynomial_data(n_samples: int, noise: int, random_state: int = 0) -> Tuple[np.ndarray, np.ndarray]:\n",
        "    \"\"\"\n",
        "    Génère un dataset suivant une courbe polynomiale\n",
        "    \"\"\"\n",
        "    rng = np.random.default_rng(random_state)\n",
        "    X = rng.uniform(-2, 2, size=(n_samples, 1))\n",
        "    x = X[:, 0]\n",
        "    y = 3 * x**3 - 2 * x**2 + x + noise * rng.normal(size=n_samples)\n",
        "    return X, y\n",
        "\n",
        "def plot_comparison(model_linear: LinearRegression, model_poly: LinearRegression, poly: PolynomialFeatures,\n",
        "                    X: np.ndarray, y: np.ndarray, degree: int):\n",
        "    \"\"\"\n",
        "    Trace les courbes de prédiction des modèles linéaire et polynomial sur une plage de valeurs,\n",
        "    ainsi que les données brutes pour comparaison.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(7, 5))\n",
        "    plt.scatter(X, y, s=10, alpha=0.4, label=\"Données brutes\")\n",
        "\n",
        "    x_line = np.linspace(X.min(), X.max(), 300).reshape(-1, 1)\n",
        "    y_line_linear = model_linear.predict(x_line)\n",
        "    x_line_poly = poly.transform(x_line)\n",
        "    y_line_poly = model_poly.predict(x_line_poly)\n",
        "\n",
        "    plt.plot(x_line, y_line_linear, color=\"blue\", lw=2, label=\"Régression linéaire\")\n",
        "    plt.plot(x_line, y_line_poly, color=\"red\", lw=2, label=f\"Régression polynomiale (deg {degree})\")\n",
        "    plt.xlabel(\"Variable explicative\")\n",
        "    plt.ylabel(\"Cible\")\n",
        "    plt.title(\"Comparaison: régression linéaire vs polynomiale\")\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "9oWHAc_eCCyK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Code à compléter"
      ],
      "metadata": {
        "id": "3F0OA7CE-Lh7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_poly(X_train: np.ndarray, y_train: np.ndarray, degree: int = 3) -> Tuple[LinearRegression, PolynomialFeatures]:\n",
        "    \"\"\"\n",
        "    Crée et entraîne un modèle de régression polynomiale.\n",
        "    Retourne le modèle et le transformateur PolynomialFeatures.\n",
        "    \"\"\"\n",
        "    # TODO: Implémenter l'entraînement du modèle de régression polynomiale\n",
        "\n",
        "    raise NotImplementedError()\n",
        "\n",
        "def eval_poly(model: LinearRegression, poly: PolynomialFeatures, X_val: np.ndarray, y_val: np.ndarray) -> dict[str, float]:\n",
        "    \"\"\"\n",
        "    Évalue le modèle de régression polynomiale sur l'ensemble de validation transformé et renvoie les métriques.\n",
        "    \"\"\"\n",
        "    # TODO: Implémenter la validation du modèle de régression polynomiale\n",
        "\n",
        "    raise NotImplementedError()\n",
        "\n",
        "def train_linear(X_train: np.ndarray, y_train: np.ndarray) -> LinearRegression:\n",
        "    \"\"\"\n",
        "    Entraîne un modèle de régression linéaire sur les données d'origine.\n",
        "    \"\"\"\n",
        "    # TODO: Implémenter l'entraînement du modèle de régression linéaire\n",
        "\n",
        "    raise NotImplementedError()\n",
        "\n",
        "def eval_linear(model: LinearRegression, X_val: np.ndarray, y_val: np.ndarray) -> dict[str, float]:\n",
        "    \"\"\"\n",
        "    Évalue le modèle de régression linéaire sur l'ensemble de validation et renvoie les métriques.\n",
        "    \"\"\"\n",
        "    # TODO: Implémenter la validation du modèle de régression linéaire\n",
        "\n",
        "    raise NotImplementedError()\n",
        "\n",
        "def main(test_ratio: float = 0.2, random_state: int = 0, degree: int = 3):\n",
        "    X, y = generate_polynomial_data(n_samples=500, noise=3)\n",
        "\n",
        "    # TODO: Séparer le jeu de données en ensembles d'entraînement et de validation\n",
        "\n",
        "    # TODO: Entraînement et évaluation du modèle de régression linéaire\n",
        "\n",
        "    # TODO: Entraînement et évaluation du modèle de régression polynomiale\n",
        "\n",
        "    # TODO: Afficher les métriques du modèle de régression linéaire\n",
        "\n",
        "    # TODO: Afficher les métriques du modèle de régression polynomiale\n",
        "\n",
        "    # TODO: Afficher les visualisations de comparaison des deux modèles\n",
        "    #       à l'aide de la fonction plot\n",
        "\n",
        "    raise NotImplementedError()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main(degree=3)"
      ],
      "metadata": {
        "id": "GPxCxqfJ-R06"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tests"
      ],
      "metadata": {
        "id": "4ivbEmh1_h3B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LIN_EXPECTED = {\n",
        "    \"rmse\": 5.4827,\n",
        "    \"mse\": 30.0603,\n",
        "    \"r2\": 0.7305,\n",
        "}\n",
        "\n",
        "POLY_EXPECTED = {\n",
        "    \"rmse\": 3.0354,\n",
        "    \"mse\": 9.2138,\n",
        "    \"r2\": 0.9174,\n",
        "}\n",
        "\n",
        "TOL = 1e-2\n",
        "\n",
        "class TestPolynomialRegression(unittest.TestCase):\n",
        "    def test_train_poly_perfect_fit(self):\n",
        "        \"\"\"Le modèle de degré 3 doit retrouver exactement la courbe cubique sans bruit.\"\"\"\n",
        "        rng = np.random.default_rng(42)\n",
        "        X = rng.uniform(-1.5, 1.5, size=(300, 1))\n",
        "        x = X[:, 0]\n",
        "        y = 3 * x**3 - 2 * x**2 + x\n",
        "\n",
        "        model, poly = train_poly(X, y, degree=3)\n",
        "        metrics = eval_poly(model, poly, X, y)\n",
        "\n",
        "        self.assertIsInstance(model, LinearRegression)\n",
        "        self.assertIsInstance(poly, PolynomialFeatures)\n",
        "\n",
        "        self.assertAlmostEqual(metrics[\"rmse\"], 0.0, delta=1e-9)\n",
        "        self.assertAlmostEqual(metrics[\"mse\"],  0.0, delta=1e-9)\n",
        "        self.assertAlmostEqual(metrics[\"r2\"],   1.0, delta=1e-9)\n",
        "\n",
        "    def test_polynomial_beats_linear_on_synthetic_data(self):\n",
        "        \"\"\"Sur un jeu de données non linéaire bruité, la régression polynomiale\n",
        "        doit surpasser la régression linéaire (meilleur R², plus petit RMSE).\"\"\"\n",
        "        X, y = generate_polynomial_data(n_samples=500, noise=3, random_state=0)\n",
        "        X_tr, X_val, y_tr, y_val = train_test_split(\n",
        "            X, y, test_size=0.2, random_state=0, shuffle=True\n",
        "        )\n",
        "\n",
        "        lin_model  = train_linear(X_tr, y_tr)\n",
        "        lin_metrics = eval_linear(lin_model, X_val, y_val)\n",
        "\n",
        "        poly_model, poly = train_poly(X_tr, y_tr, degree=3)\n",
        "        poly_metrics = eval_poly(poly_model, poly, X_val, y_val)\n",
        "\n",
        "        self.assertLess(poly_metrics[\"rmse\"], lin_metrics[\"rmse\"],\n",
        "                        msg=\"Le modèle polynomial devrait réduire le RMSE.\")\n",
        "        self.assertGreater(poly_metrics[\"r2\"], lin_metrics[\"r2\"],\n",
        "                           msg=\"Le modèle polynomial devrait augmenter le R².\")\n",
        "\n",
        "        for key, expected in LIN_EXPECTED.items():\n",
        "            self.assertAlmostEqual(lin_metrics[key], expected, delta=TOL,\n",
        "                                   msg=f\"Dérive détectée pour {key} (linéaire).\")\n",
        "        for key, expected in POLY_EXPECTED.items():\n",
        "            self.assertAlmostEqual(poly_metrics[key], expected, delta=TOL,\n",
        "                                   msg=f\"Dérive détectée pour {key} (polynomial).\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    unittest.main(argv=[\"first-arg-is-ignored\", \"TestPolynomialRegression\"], exit=False, verbosity=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dix813CL_j5g",
        "outputId": "a4c4142d-63a8-4945-d6b8-eb8a7fc8e8d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "test_polynomial_beats_linear_on_synthetic_data (__main__.TestPolynomialRegression.test_polynomial_beats_linear_on_synthetic_data)\n",
            "Sur un jeu de données non linéaire bruité, la régression polynomiale ... ok\n",
            "test_train_poly_perfect_fit (__main__.TestPolynomialRegression.test_train_poly_perfect_fit)\n",
            "Le modèle de degré 3 doit retrouver exactement la courbe cubique sans bruit. ... ok\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "Ran 2 tests in 0.019s\n",
            "\n",
            "OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Régression logistique\n",
        "\n",
        "Dans cet exercice, vous allez construire un modèle de *machine learning* pour **prédire si une tumeur est maligne (1) ou bénigne (0)** à partir de deux mesures morphologiques : `mean radius` et `mean texture`.  \n",
        "Le modèle choisi est la **régression logistique**, qui est bien adaptée aux problèmes de classification binaire.\n",
        "\n",
        "### Objectifs pédagogiques\n",
        "1. **Comprendre** les étapes clés d'un workflow de classification :  \n",
        "   préparation des données, normalisation, entraînement, validation et visualisation.  \n",
        "2. **Implémenter** les fonctions `train`, `eval` et `main` afin de :  \n",
        "   - séparer le jeu de données en `train` / `validation` (`train_test_split`) ;  \n",
        "   - normaliser les variables explicatives avec `StandardScaler` ;  \n",
        "   - entraîner un modèle `LogisticRegression` de *scikit-learn* ;  \n",
        "   - calculer et afficher les métriques : **Accuracy**, **Precision**, **Recall**, **F1** et la **matrice de confusion**.  \n",
        "3. **Analyser** les performances du modèle : examiner la **matrice de confusion** et les **métriques** (Accuracy, Precision, Recall, F1) afin de repérer faux positifs / faux négatifs et juger la qualité globale de la classification.\n",
        "\n",
        "### Jeu de données\n",
        "Nous utiliserons le **Breast Cancer Wisconsin Dataset** fourni par *scikit-learn*.\n",
        "\n",
        "*Référence utile : https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html*"
      ],
      "metadata": {
        "id": "gM3EkSfwAjFx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Code fourni"
      ],
      "metadata": {
        "id": "0AsX8oTHJV9L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot(model: LogisticRegression, scaler: StandardScaler, X: np.ndarray, y: np.ndarray):\n",
        "    plt.figure(figsize=(7, 5))\n",
        "    plt.scatter(\n",
        "        X[:, 0], X[:, 1],\n",
        "        c=y, cmap=\"bwr\", alpha=0.6, edgecolor=\"k\", s=35, label=\"Données\"\n",
        "    )\n",
        "\n",
        "    x_min, x_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5\n",
        "    y_min, y_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5\n",
        "    xx, yy = np.meshgrid(\n",
        "        np.linspace(x_min, x_max, 300),\n",
        "        np.linspace(y_min, y_max, 300)\n",
        "    )\n",
        "    grid_std = scaler.transform(np.c_[xx.ravel(), yy.ravel()])\n",
        "    Z = model.predict(grid_std).reshape(xx.shape)\n",
        "\n",
        "    plt.contourf(xx, yy, Z, levels=[-1, 0, 1], alpha=0.15, cmap=\"bwr\")\n",
        "    plt.xlabel(\"Rayon moyen\")\n",
        "    plt.ylabel(\"Texture moyenne\")\n",
        "    plt.title(\"Cancer du sein - Régression logistique\")\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "qAIzEg15JaFh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Code à compléter"
      ],
      "metadata": {
        "id": "IhRTwLvRJXyg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(X_train: np.ndarray, y_train: np.ndarray) -> LogisticRegression:\n",
        "    \"\"\"\n",
        "    Crée et entraîne un modèle de régression logistique.\n",
        "    Retourne le modèle entraîné.\n",
        "    \"\"\"\n",
        "\n",
        "    # TODO: Effectuer la régression logistique sur l'ensemble d'entraînement\n",
        "\n",
        "    raise NotImplementedError()\n",
        "\n",
        "def eval(model: LogisticRegression, X_val: np.ndarray, y_val: np.ndarray) -> dict[str, float]:\n",
        "    \"\"\"\n",
        "    Évalue le modèle sur l'ensemble de validation et retourne les métriques\n",
        "    (Accuracy, Precision, Recall, F1).\n",
        "    \"\"\"\n",
        "\n",
        "    # TODO: Effectuer la validation du modèle sur l'ensemble de validation\n",
        "\n",
        "    raise NotImplementedError()\n",
        "\n",
        "def main(test_ratio: float = 0.2, random_state: int = 0):\n",
        "    data = load_breast_cancer()\n",
        "    features = [\"mean radius\", \"mean texture\"]\n",
        "    idx = [list(data.feature_names).index(f) for f in features]\n",
        "    X = data.data[:, idx]\n",
        "    y = data.target\n",
        "\n",
        "    # TODO: Séparer votre jeu de données en ensemble d'entraînement et de validation\n",
        "\n",
        "    # TODO: Normaliser vos variables explicatives\n",
        "\n",
        "    # TODO: Instancier votre modèle entraîné et effectuer la validation du modèle\n",
        "\n",
        "    # TODO: Afficher les métriques et la matrice de confusion\n",
        "\n",
        "    # TODO: Afficher les visualisations à partir de la fonction plot\n",
        "\n",
        "    raise NotImplementedError()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "aDAAKHFiJa1d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tests"
      ],
      "metadata": {
        "id": "0V_z2B6wJbTP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EXPECTED = {\n",
        "    \"Accuracy\":  0.8684,\n",
        "    \"Precision\": 0.9014,\n",
        "    \"Recall\":    0.8889,\n",
        "    \"F1\":        0.8951,\n",
        "    \"conf_mat\":  np.array([[35, 7],\n",
        "                           [ 8, 64]]),\n",
        "}\n",
        "\n",
        "TOL = 1e-2\n",
        "\n",
        "class TestLogisticRegression(unittest.TestCase):\n",
        "    def test_train_perfect_separation(self):\n",
        "        rng = np.random.default_rng(0)\n",
        "        X_pos = rng.normal(loc=+2.0, scale=0.2, size=(50, 2))\n",
        "        X_neg = rng.normal(loc=-2.0, scale=0.2, size=(50, 2))\n",
        "        X = np.vstack([X_pos, X_neg])\n",
        "        y = np.hstack([np.ones(50), np.zeros(50)])\n",
        "\n",
        "        scaler = StandardScaler()\n",
        "        X_std = scaler.fit_transform(X)\n",
        "\n",
        "        model = train(X_std, y)\n",
        "        metrics = eval(model, X_std, y)\n",
        "\n",
        "        self.assertIsInstance(model, LogisticRegression)\n",
        "        for m in (\"Accuracy\", \"Precision\", \"Recall\", \"F1\"):\n",
        "            self.assertAlmostEqual(metrics[m], 1.0, delta=1e-6,\n",
        "                                   msg=f\"{m} should be 1.0 on separable data\")\n",
        "\n",
        "    def test_breast_cancer_expected_metrics(self):\n",
        "        data = load_breast_cancer()\n",
        "        features = [\"mean radius\", \"mean texture\"]\n",
        "        idx = [list(data.feature_names).index(f) for f in features]\n",
        "        X = data.data[:, idx]\n",
        "        y = data.target\n",
        "\n",
        "        X_tr, X_val, y_tr, y_val = train_test_split(\n",
        "            X, y, test_size=0.2, random_state=0, stratify=y\n",
        "        )\n",
        "\n",
        "        scaler = StandardScaler()\n",
        "        X_tr_std = scaler.fit_transform(X_tr)\n",
        "        X_val_std = scaler.transform(X_val)\n",
        "\n",
        "        model = train(X_tr_std, y_tr)\n",
        "        metrics = eval(model, X_val_std, y_val)\n",
        "\n",
        "        for key in (\"Accuracy\", \"Precision\", \"Recall\", \"F1\"):\n",
        "            self.assertAlmostEqual(metrics[key], EXPECTED[key], delta=TOL,\n",
        "                                   msg=f\"Dérive détectée pour {key}\")\n",
        "\n",
        "        conf = confusion_matrix(y_val, model.predict(X_val_std))\n",
        "        self.assertTrue(np.array_equal(conf, EXPECTED[\"conf_mat\"]),\n",
        "                        msg=\"Matrice de confusion différente des valeurs de référence\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    unittest.main(argv=[\"first-arg-is-ignored\", \"TestLogisticRegression\"], exit=False, verbosity=2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jsuld5HNJdp1",
        "outputId": "d507ede6-8f0b-4a32-8a34-57115de44bba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "test_breast_cancer_expected_metrics (__main__.TestLogisticRegression.test_breast_cancer_expected_metrics) ... ok\n",
            "test_train_perfect_separation (__main__.TestLogisticRegression.test_train_perfect_separation) ... ok\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "Ran 2 tests in 0.051s\n",
            "\n",
            "OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Réseaux de neurones\n",
        "\n",
        "Dans cet exercice, vous allez implémenter un **réseau de neurones** pour effectuer une tâche de **classification d'images** sur le dataset MNIST, qui contient des images de chiffres manuscrits (0 à 9).\n",
        "\n",
        "Le modèle utilisé est un **réseau de neurones entièrement connecté** (MLP - Multi-Layer Perceptron), construit avec **PyTorch**. Il est composé de plusieurs couches linéaires avec des fonctions d'activation non-linéaires.\n",
        "\n",
        "### Objectifs pédagogiques\n",
        "\n",
        "Apprendre les étapes clés d'un workflow de deep learning :\n",
        "\n",
        "- Charger et transformer les données MNIST (`transforms.ToTensor`)\n",
        "- Construire un réseau de neurones avec `torch.nn.Module`\n",
        "- Entraîner (`train`) et évaluer (`eval`) le modèle avec `CrossEntropyLoss` et un optimiseur (`Adam`)\n",
        "- Mesurer les performances (Accuracy)\n",
        "- Visualiser les prédictions sur des exemples d'images\n",
        "\n",
        "Vous implémenterez les fonctions `train`, `eval` et `main` pour réaliser ce processus de bout en bout.\n",
        "\n",
        "### Jeu de données\n",
        "\n",
        "Nous utiliserons le dataset **MNIST** fourni par `torchvision.datasets`.\n",
        "\n",
        "*Référence utile : https://docs.pytorch.org/tutorials/beginner/basics/intro.html*\n"
      ],
      "metadata": {
        "id": "CmRBeV2xAlhc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Code fourni"
      ],
      "metadata": {
        "id": "4eHsndNPBI0i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_examples(images, labels, preds=None, n=6):\n",
        "    plt.figure(figsize=(10, 2))\n",
        "\n",
        "    for i in range(n):\n",
        "        plt.subplot(1, n, i + 1)\n",
        "        plt.imshow(images[i][0], cmap=\"gray\")\n",
        "        title = f\"{labels[i]}\"\n",
        "\n",
        "        if preds is not None:\n",
        "            title += f\"→{preds[i]}\"\n",
        "\n",
        "        plt.title(title)\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "YAaRl0hYBGcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Code à compléter"
      ],
      "metadata": {
        "id": "Wz3S_HsRBLSr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNet(nn.Module):\n",
        "    # TODO: Implémenter l'architecture du réseau de neurones\n",
        "    def __init__(self):\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def forward(self, x):\n",
        "        raise NotImplementedError()\n",
        "\n",
        "\n",
        "def train(model, loader, criterion, optimizer, epoch):\n",
        "    model.train()\n",
        "\n",
        "    # TODO: Implémenter l'entraînement de votre modèle\n",
        "    raise NotImplementedError()\n",
        "\n",
        "\n",
        "def eval(model, loader, criterion):\n",
        "    model.eval()\n",
        "\n",
        "    # TODO: Implémenter la validation de votre modèle\n",
        "    raise NotImplementedError()\n",
        "\n",
        "def main(batch_size=128, epochs=5, lr=1e-3, random_state=0):\n",
        "    torch.manual_seed(random_state)\n",
        "\n",
        "    transform = transforms.ToTensor()\n",
        "\n",
        "    train_ds = datasets.MNIST(root=\"data\", train=True, download=True, transform=transform)\n",
        "    test_ds = datasets.MNIST(root=\"data\", train=False, download=True, transform=transform)\n",
        "\n",
        "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True,  num_workers=2)\n",
        "    test_loader = DataLoader(test_ds,  batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "    # TODO: Instancier votre modèle, votre perte et votre optimiseur\n",
        "\n",
        "    # TODO: Effectuer l'entraînement et la validation de votre modèle\n",
        "\n",
        "    raise NotImplementedError()\n",
        "\n",
        "    sample_imgs, sample_labels = next(iter(test_loader))[:6]\n",
        "    sample_preds = model(sample_imgs.to(DEVICE)).argmax(1).cpu()\n",
        "    plot_examples(sample_imgs, sample_labels, sample_preds)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "dH16CEVTAqMD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tests"
      ],
      "metadata": {
        "id": "mjQUYT-0M15s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TOL = 1e-3\n",
        "\n",
        "class TestNeuralNetworks(unittest.TestCase):\n",
        "    def setUp(self):\n",
        "        self.model = NeuralNet().to(DEVICE)\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=1e-3)\n",
        "\n",
        "        x = torch.randn(10, 1, 28, 28).to(DEVICE)\n",
        "        y = torch.arange(10).to(DEVICE)\n",
        "        self.loader = DataLoader(TensorDataset(x, y), batch_size=5)\n",
        "\n",
        "    def test_forward_output_shape(self):\n",
        "        for xb, _ in self.loader:\n",
        "            out = self.model(xb)\n",
        "            self.assertEqual(out.shape, (xb.size(0), 10))\n",
        "\n",
        "    def test_train_reduces_loss(self):\n",
        "        xb, yb = next(iter(self.loader))\n",
        "        self.model.train()\n",
        "        initial_loss = self.criterion(self.model(xb), yb).item()\n",
        "\n",
        "        train(self.model, self.loader, self.criterion, self.optimizer, epoch=1)\n",
        "\n",
        "        new_loss = self.criterion(self.model(xb), yb).item()\n",
        "        self.assertLessEqual(new_loss, initial_loss + TOL)\n",
        "\n",
        "    def test_eval_returns_correct_format(self):\n",
        "        y_true, y_pred = eval(self.model, self.loader, self.criterion)\n",
        "        self.assertIsInstance(y_true, np.ndarray)\n",
        "        self.assertIsInstance(y_pred, np.ndarray)\n",
        "        self.assertEqual(len(y_true), len(y_pred))\n",
        "        self.assertTrue(((y_pred >= 0) & (y_pred < 10)).all())\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    unittest.main(\n",
        "        argv=[\"first-arg-is-ignored\", \"TestNeuralNetworks\"],\n",
        "        exit=False,\n",
        "        verbosity=2,\n",
        "    )"
      ],
      "metadata": {
        "id": "DBINYQs6M37c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28819370-bb73-49e2-a1b8-5c251633cc52"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "test_eval_returns_correct_format (__main__.TestNeuralNetworks.test_eval_returns_correct_format) ... ok\n",
            "test_forward_output_shape (__main__.TestNeuralNetworks.test_forward_output_shape) ... ok\n",
            "test_train_reduces_loss (__main__.TestNeuralNetworks.test_train_reduces_loss) ... ok\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "Ran 3 tests in 0.073s\n",
            "\n",
            "OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation - loss: 2.2866 | acc: 0.0000\n",
            "[Epoch 1] train loss: 2.2903\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Arbres de décision\n",
        "\n",
        "\n",
        "Dans cet exercice, vous allez comparer plusieurs **modèles à base d'arbres de décision** pour prédire le **prix médian des maisons en Californie**.  \n",
        "L'idée est de mesurer l'apport de techniques plus sophistiquées (forêt aléatoire, gradient boosting) par rapport à une **régression linéaire** de référence.\n",
        "\n",
        "### Objectifs pédagogiques\n",
        "1. **Comprendre** les étapes essentielles d'un workflow de *machine learning* :  préparation des données, entraînement, validation et visualisation.\n",
        "2. **Implémenter** les fonctions génériques `train`, `eval` et `main` pour :  \n",
        "   - instancier plusieurs modèles (`LinearRegression`, `DecisionTreeRegressor`, `RandomForestRegressor`, `GradientBoostingRegressor`) ;  \n",
        "   - calculer et afficher les métriques : **RMSE**, **MSE** et **R²** ;  \n",
        "   - tracer un nuage **valeurs réelles vs prédictions** pour chaque modèle.  \n",
        "3. **Comparer** l'impact de la complexité du modèle :  \n",
        "   - montrer le gain de performance des modèles d'ensemble.\n",
        "\n",
        "### Jeu de données\n",
        "Nous utiliserons le **California Housing Dataset** fourni par *scikit-learn*.\n",
        "\n",
        "*Références utiles*\n",
        "- https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html\n",
        "- https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html\n",
        "- https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html\n",
        "\n"
      ],
      "metadata": {
        "id": "M7d_dPOqAqwc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Code fourni"
      ],
      "metadata": {
        "id": "w9SnU6FMCLJP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot(y_true: np.ndarray, y_pred: np.ndarray, title: str):\n",
        "    plt.figure(figsize=(7, 5))\n",
        "    plt.scatter(y_true, y_pred, s=10, alpha=0.5)\n",
        "    plt.plot([y_true.min(), y_true.max()], [y_true.min(), y_true.max()], color=\"red\", lw=2, label=\"y = ŷ\")\n",
        "    plt.xlabel(\"Valeurs réelles\")\n",
        "    plt.ylabel(\"Valeurs prédites\")\n",
        "    plt.title(title)\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def create_model(name: str, model_class, X_train: np.ndarray, y_train: np.ndarray, X_val: np.ndarray, y_val: np.ndarray, **kwargs):\n",
        "    print(f\"\\n----- {name} -----\")\n",
        "    model = train(model_class, X_train, y_train, **kwargs)\n",
        "    results = eval(model, X_val, y_val)\n",
        "\n",
        "    print(f\"Validation RMSE : {results['rmse']:.4f}\")\n",
        "    print(f\"Validation MSE  : {results['mse']:.4f}\")\n",
        "    print(f\"Validation R²   : {results['r2']:.4f}\")\n",
        "\n",
        "    plot(y_val, results[\"y_pred\"], f\"Prédictions vs Réel - {name}\")"
      ],
      "metadata": {
        "id": "3HnlKxqfCKYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Code à compléter"
      ],
      "metadata": {
        "id": "7cHwjdXkCUVm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model_class, X_train: np.ndarray, y_train: np.ndarray, **kwargs):\n",
        "    # TODO: Implémenter l'entraînement du modèle\n",
        "    raise NotImplementedError()\n",
        "\n",
        "def eval(model, X_val: np.ndarray, y_val: np.ndarray) -> dict[str, float]:\n",
        "    # TODO: Implémenter la validation du modèle\n",
        "    raise NotImplementedError()\n",
        "\n",
        "def main(test_ratio: float = 0.2, random_state: int = 0):\n",
        "    data = fetch_california_housing()\n",
        "    X = data.data\n",
        "    y = data.target\n",
        "\n",
        "    # TODO: Séparer votre jeu de données en ensembles d'entraînement et de validation\n",
        "\n",
        "    # TODO: Instancier, entraîner et valider les modèles suivants à partir de la fonction create_model:\n",
        "    #       Régression linéaire, Arbre de décision, Forêt aléatoire, Gradient boosting\n",
        "    #       Indice: Passez la classe du modèle (et non une instance) comme deuxième argument de\n",
        "    #       create_model.  La fonction se chargera de l’instancier via train(...).\n",
        "    #       Exemple : create_model(\"Régression linéaire\", LinearRegression, ...).\n",
        "    #       Ajoutez les hyperparamètres éventuels dans kwargs (après X_val, y_val).\n",
        "\n",
        "    raise NotImplementedError()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "T3RfONHmCWj6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tests"
      ],
      "metadata": {
        "id": "_nXkomwACeDo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EXPECTED = {\n",
        "    \"LinearRegression\": {\"rmse\": 0.7273, \"mse\": 0.5290, \"r2\": 0.5943},\n",
        "    \"DecisionTree\":     {\"rmse\": 0.7290, \"mse\": 0.5315, \"r2\": 0.5924},\n",
        "    \"RandomForest\":     {\"rmse\": 0.5131, \"mse\": 0.2633, \"r2\": 0.7981},\n",
        "    \"GradientBoosting\": {\"rmse\": 0.5388, \"mse\": 0.2903, \"r2\": 0.7774},\n",
        "}\n",
        "\n",
        "TOL = 1e-2\n",
        "\n",
        "class TestTreeBasedModels(unittest.TestCase):\n",
        "    def test_linear_regression_perfect_fit(self):\n",
        "        rng = np.random.default_rng(1)\n",
        "        X = rng.random((80, 3))\n",
        "        coeff = rng.random(3)\n",
        "        y = X @ coeff\n",
        "        model = train(LinearRegression, X, y)\n",
        "        metrics = eval(model, X, y)\n",
        "        for key in (\"rmse\", \"mse\"):\n",
        "            self.assertAlmostEqual(metrics[key], 0.0, delta=TOL)\n",
        "        self.assertAlmostEqual(metrics[\"r2\"], 1.0, delta=TOL)\n",
        "\n",
        "    def test_decision_tree_perfect_fit(self):\n",
        "        rng = np.random.default_rng(2)\n",
        "        X = rng.random((100, 2))\n",
        "        y = rng.random(100)\n",
        "        model = train(DecisionTreeRegressor, X, y, random_state=0)\n",
        "        metrics = eval(model, X, y)\n",
        "        for key in (\"rmse\", \"mse\"):\n",
        "            self.assertAlmostEqual(metrics[key], 0.0, delta=TOL)\n",
        "        self.assertAlmostEqual(metrics[\"r2\"], 1.0, delta=TOL)\n",
        "\n",
        "    def test_random_forest_perfect_fit(self):\n",
        "        rng = np.random.default_rng(3)\n",
        "        X = rng.random((60, 4))\n",
        "        y = rng.random(60)\n",
        "        model = train(\n",
        "            RandomForestRegressor,\n",
        "            X,\n",
        "            y,\n",
        "            n_estimators=1,\n",
        "            bootstrap=False,\n",
        "            random_state=0,\n",
        "        )\n",
        "        metrics = eval(model, X, y)\n",
        "        for key in (\"rmse\", \"mse\"):\n",
        "            self.assertAlmostEqual(metrics[key], 0.0, delta=TOL)\n",
        "        self.assertAlmostEqual(metrics[\"r2\"], 1.0, delta=TOL)\n",
        "\n",
        "    def test_gradient_boosting_perfect_fit(self):\n",
        "        rng = np.random.default_rng(4)\n",
        "        X = rng.random((50, 2))\n",
        "        y = rng.random(50)\n",
        "        model = train(\n",
        "            GradientBoostingRegressor,\n",
        "            X,\n",
        "            y,\n",
        "            n_estimators=500,\n",
        "            learning_rate=1.0,\n",
        "            max_depth=3,\n",
        "            random_state=0,\n",
        "        )\n",
        "        metrics = eval(model, X, y)\n",
        "        for key in (\"rmse\", \"mse\"):\n",
        "            self.assertAlmostEqual(metrics[key], 0.0, delta=TOL)\n",
        "        self.assertAlmostEqual(metrics[\"r2\"], 1.0, delta=TOL)\n",
        "\n",
        "    def test_expected_metrics_california(self):\n",
        "        data = fetch_california_housing()\n",
        "        X, y = data.data, data.target\n",
        "        X_tr, X_val, y_tr, y_val = train_test_split(\n",
        "            X,\n",
        "            y,\n",
        "            test_size=0.2,\n",
        "            random_state=0,\n",
        "            shuffle=True,\n",
        "        )\n",
        "        suite = [\n",
        "            (\"LinearRegression\", LinearRegression, {}),\n",
        "            (\"DecisionTree\", DecisionTreeRegressor, {\"random_state\": 0}),\n",
        "            (\n",
        "                \"RandomForest\",\n",
        "                RandomForestRegressor,\n",
        "                {\"n_estimators\": 100, \"random_state\": 0},\n",
        "            ),\n",
        "            (\n",
        "                \"GradientBoosting\",\n",
        "                GradientBoostingRegressor,\n",
        "                {\"n_estimators\": 100, \"random_state\": 0},\n",
        "            ),\n",
        "        ]\n",
        "        for name, cls, kwargs in suite:\n",
        "            model = train(cls, X_tr, y_tr, **kwargs)\n",
        "            metrics = eval(model, X_val, y_val)\n",
        "            for key in (\"rmse\", \"mse\", \"r2\"):\n",
        "                self.assertAlmostEqual(metrics[key], EXPECTED[name][key], delta=TOL)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    unittest.main(\n",
        "        argv=[\"first-arg-is-ignored\", \"TestTreeBasedModels\"],\n",
        "        exit=False,\n",
        "        verbosity=2,\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4avEBsRqWY_k",
        "outputId": "e3f4ceb3-48e0-4185-cb56-e8e67176b7db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "test_decision_tree_perfect_fit (__main__.TestTreeBasedModels.test_decision_tree_perfect_fit) ... ok\n",
            "test_expected_metrics_california (__main__.TestTreeBasedModels.test_expected_metrics_california) ... ok\n",
            "test_gradient_boosting_perfect_fit (__main__.TestTreeBasedModels.test_gradient_boosting_perfect_fit) ... ok\n",
            "test_linear_regression_perfect_fit (__main__.TestTreeBasedModels.test_linear_regression_perfect_fit) ... ok\n",
            "test_random_forest_perfect_fit (__main__.TestTreeBasedModels.test_random_forest_perfect_fit) ... ok\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "Ran 5 tests in 26.950s\n",
            "\n",
            "OK\n"
          ]
        }
      ]
    }
  ]
}